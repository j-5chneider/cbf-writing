---
title: "Computer-based formative feedback on writing"
author:
- affiliation: University of Tübingen
  email: salome.wagner@uni-tuebingen.de
  name: Salome Wagner
  url: https://uni-tuebingen.de/de/172926
- affiliation: University of Tübingen
  email: juergen.schneider@uni-tuebingen.de
  name: Jürgen Schneider
  url: https://uni-tuebingen.de/de/175743
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    highlight: espresso
    number_sections: yes
    theme: paper
    toc: yes
    toc_depth: 2
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '2'
description: ""
css: www/style.css
---

```{r setup, echo=F, message=F, warning=F, comment=F}
knitr::opts_chunk$set(echo = F, message = F, warning = F)
library(pander)
library(dplyr)
library(kableExtra)
```

\
\
\

<div style="padding: 5px; background-color: #F0F0F0;">
__This is__ a Rmd-template for protocols and reporting of systematic reviews and meta-analyses. It synthesizes three sources of standards:

* [PRISMA-P](https://doi.org/10.1136/bmj.i4086)
* [PROSPERO](https://www.crd.york.ac.uk/prospero/)
* [MARS](https://doi.org/10.1037/amp0000389)

The template is __aimed at__

* guiding the process of planning the systemtic review/ meta-analysis
* providing a form for preregistration (enter your text, export as standalone html, upload as preregistration)

We are aware that MARS targets aspects of reporting after the systemtic review/ meta-analysis is completed rather than decisions and reasoning in the planning phase as PRISMA-P and PROSPERO. MARS nevertheless provides a good framework to determine crucial points for systemtic reviews/ meta-analyses to be addressed as early as in the planning phase.
</div>

  
_Standards have been partially adapted. Click 'show changes' to see changes and reasons for change._  

<button data-toggle="collapse" data-target="#changes">show changes</button>
<div id="changes" class="collapse">
| standard |  implemented change  | reason                      |
|:---------|:---------------------|:----------------------------|
| MARS |  Left out paper section "Abstract"  |  An abstract is important for reporting, not however, for planning and registering. |
| MARS |  Left out paper section "Results" and parts of "Discussion"  |  Specifications on how to report results is important for reporting, not however, for planning and registering. Prospective information on how results will be computed/ synthesized is preserved. |
| MARS | Left out "Protocol: List where the full protocol can be found" | This form practically is the protocol. |
|  PROSPERO  |  Left out non-mandatory fields or integrated them with mandatory fields.  |  Avoiding too detailed specifications. All relevant informations will be integrated. |
| PROSPERO | Left out some options in "Type and method of review" | Options left out are purely health/ medicine related. |
| PROSPERO | Left out "Health area of the review" | This field is purely health/ medicine related. |


</div>

\
\
\


# General 

## Working Title

<button data-toggle="collapse" data-target="#wt">more info</button>
<div id="wt" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Identify the report as a protocol of a systematic review. If the protocol is for an update of a previous systematic review, identify as such",
                                            # PROSPERO
                                            "Give the working title of the review, for example the one used for obtaining funding. Ideally the title should state succinctly the interventions or exposures being reviewed and the associated health or social problems. Where appropriate, the title should use the PI(E)COS structure to contain information on the Participants, Intervention (or Exposure) and Comparison groups, the Outcomes to be measured and Study designs to be included.

For reviews in languages other than English, this field should be used to enter the title in the language of the
review. This will be displayed together with the English language title.",
                                            # MARS
                                            "Title: State the research question and type of research synthesis (e.g., narrative synthesis, meta-analysis)"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Where to Next? Mapping the Landscape of Research on Computer-Based Feedback on Writing. A Systematic Review.


## Type of Review

<button data-toggle="collapse" data-target="#typeor">more info</button>
<div id="typeor" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Type and method of review: Select the type of review and the review method from the lists below. Select the health area(s) of interest for your review.

* Meta-analysis
* Narrative synthesis
* Network meta-analysis
* Review of reviews
* Synthesis of qualitative studies
* Systematic review
* Other",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Systematic review.



## Link to Registration

<button data-toggle="collapse" data-target="#ltr">more info</button>
<div id="ltr" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "If registered, provide the name of the registry (such as PROSPERO) and registration number.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Give the place where the synthesis is registered and its registry number, if registered"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

We use this form as registration.


## Anticipated start and completion date

<button data-toggle="collapse" data-target="#aasd">more info</button>
<div id="aasd" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Give the date when the systematic review commenced, or is expected to commence. Give the date by which the review is expected to be completed.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

__Start:__ July 2020  
__Anticipated Completion Date:__ January 2021



## Stage of Review

<button data-toggle="collapse" data-target="#sor">more info</button>
<div id="sor" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Indicate the stage of progress of the review by ticking the relevant Started and Completed boxes. Additional
information may be added in the free text box provided.
Please note: Reviews that have progressed beyond the point of completing data extraction at the time of
initial registration are not eligible for inclusion in PROSPERO. Should evidence of incorrect status and/or
completion date being supplied at the time of submission come to light, the content of the PROSPERO
record will be removed leaving only the title and named contact details and a statement that inaccuracies in
the stage of the review date had been identified.
This field should be updated when any amendments are made to a published record and on completion and
publication of the review. If this field was pre-populated from the initial screening questions then you are not
able to edit it until the record is published.

* The review has not yet started: [yes/no]

| Review stage | Started | Completed |
|:--------------------------------------------| :----:| :----:|
| Preliminary searches | Yes/No | Yes/No
| Piloting of the study selection process | Yes/No | Yes/No
| Formal screening of search results against eligibility criteria | Yes/No | Yes/No
| Data extraction | Yes/No | Yes/No
| Risk of bias (quality) assessment | Yes/No | Yes/No
| Data analysis | Yes/No | Yes/No

Provide any other relevant information about the stage of the review here (e.g. Funded proposal, protocol not
yet finalised).",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources, escape = F) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

The review has not yet started [yes/no]: no

| Review stage | Started | Completed |
|:--------------------------------------------| :----:| :----:|
| Preliminary searches | Yes | No
| Piloting of the study selection process | No | No
| Formal screening of search results against eligibility criteria | No | No
| Data extraction | No | No
| Risk of bias (quality) assessment | No | No
| Data analysis | No | No


## Names, Affiliations, Contact

<button data-toggle="collapse" data-target="#nac">more info</button>
<div id="nac" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "
* Provide name, institutional affiliation, e-mail address of all protocol authors; provide physical mailing address of corresponding author.
* Describe contributions of protocol authors and identify the guarantor of the review.",
                                            # PROSPERO
                                            "
* Named Contact: The named contact acts as the guarantor for the accuracy of the information presented in the register record.
* Named contact email: Give the electronic mail address of the named contact.
* Organisational affiliation of the review: Full title of the organisational affiliations for this review and website address if available. This field may be completed as 'None' if the review is not affiliated to any organisation.
* Review team members and their organisational affiliations: Give the personal details and the organisational affiliations of each member of the review team. Affiliation refers to groups or organisations to which review team members belong.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

* Named contact: Salome Wagner
* Named contact email: salome.wagner@uni-tuebingen.de
* Named contact ORCID: [0000-0002-5839-7827](https://orcid.org/0000-0002-5839-7827)
* Organisational affiliation of the review: University of Tübingen, Germany
* Review team members and their organisational affiliations:
  - Jürgen Schneider, juergen.schneider@uni-tuebingen.de, ORCID [0000-0002-3772-4198](https://orcid.org/0000-0002-3772-4198)
  - Andreas Lachner, andreas.lachner@uni-tuebingen.de

## Collaborators

<button data-toggle="collapse" data-target="#colla">more info</button>
<div id="colla" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Collaborators (name & affilitation) of individuals working on the review, but are not review team member.",
                                            # MARS
                                            "Not specified."))
# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

* Name: pending
* Email: pending
* ORCID: pending
* Affiliation: pending


## Amendments to previous versions

<button data-toggle="collapse" data-target="#atpv">more info</button>
<div id="atpv" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "If the protocol represents an amendment of a previously completed or published protocol, identify as such and list changes; otherwise, state plan for documenting important protocol amendments.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Amendments will be published as new version of the document under the same DOI (or will point to previous version).


## Funding sources, sponsors and their roles

<button data-toggle="collapse" data-target="#fsign">more info</button>
<div id="fsign" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "
* Indicate sources of financial or other support for the review
* Provide name for the review funder and/or sponsor
* Describe roles of funder(s), sponsor(s), and/or institution(s), if any, in developing the protocol",
                                            # PROSPERO
                                            "Funding sources/sponsors: Give details of the individuals, organizations, groups or other legal entities who take responsibility for initiating, managing, sponsoring and/or financing the review. Include any unique identification numbers assigned to the review by the individuals or bodies listed. Grant numbers.",
                                            # MARS
                                            "
* List all sources of monetary and in-kind funding support
* State the role of funders in conducting the synthesis and deciding to publish the results, if any"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

No external funding.

## Conflict of Interest

<button data-toggle="collapse" data-target="#coi">more info</button>
<div id="coi" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "List any conditions that could lead to actual or perceived undue influence on judgements concerning the main topic investigated in the review.",
                                            # MARS
                                            "Describe possible conflicts of interest, including financial and other nonfinancial interests."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

No conflict of interest.


# Introduction

## Rationale

<button data-toggle="collapse" data-target="#ram">more info</button>
<div id="ram" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe the rationale for the review in the context of what is already known.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Problem: State the question or relation(s) under investigation, including

* Historical background, including previous syntheses and meta-analyses related to the topic 
* Theoretical, policy, and/or practical issues related to the question or relation(s) of interest
* Populations and settings to which the question or relation(s) is relevant
* Rationale for
   (a) choice of study designs, 
   (b) the selection and coding of outcomes, 
   (c) the selection and coding potential moderators or mediators of results 
* Psychometric characteristics of outcome measures and other variables
"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

We define feedback as information on one's performance, provided by an external agent (e.g. teacher, program) regarding designated success criteria of the performance (Kluger & DeNisi, 1996). Feedback therefore necessarily follows performance (see fig. 1). When performance follows a task, success criteria can be explicitly (e.g. “I want you to write an essay with high cohesion on the topic … .”) or implicitly (e.g. “I want you to write a good essay on the topic … .”) addressed in the task.  
  
The goal of feedback is to help the recipient to reduce discrepancies between the actual performance and the targeted performance measured via the success criteria (Hattie & Timperley, 2007). Feedback therefore includes not only assessment (or evaluation) of the performance against the success criteria, but also cues on how to reduce the discrepancies (e.g. by knowledge about solutions; Winne & Butler, 1994; Stevenson & Phakiti, 2014).  
  
The use (or uptake, implementation) of feedback by the recipient depends on properties of the feedback (e.g. specifity) as well as personal traits of the recipient (e.g. effort invested; Patchan, Shunn & Correnti, 2016; Kluger & DeNisi, 1996). Feedback use can be mediated by an instructor who pedagogically scaffolds the presentation of the feedback or scaffold peers to give each other feedback. Both types of feedback - the instructor mediated and the peer-feedback - are not part of our investigations. Instead, we focus on computer-based feedback provided by a system. 
  

<iframe width="650" height="400" src="https://prezi.com/view/c09BOfUAMMgfvM4JmYuk/embed" webkitallowfullscreen="1" mozallowfullscreen="1" allowfullscreen="1"></iframe>  
__Fig. 1:__ Proposed process of feedback

\

Software that takes the role of the feedback providing agent (computer-based feedback) usually utilize machine learning algorithms and combine several advantages:

* they remove the knowledge barrier (e.g. knowledge on success criteria or diagnostic skills)
* they give immediate feedback
* the feedback (output) is consistent for the same input

In our review we focus on computer-based systems that give feedback on writing, which are not without critique. Several studies have shown that they are not able to recognize crucial qualities of writing (Byrne, Tang, Truduc, & Tang, 2010) or use reductive measures for scoring complex skills (Perelman, 2012), just to name a few (see also: Petition against automated scoring systems: http://humanreaders.org/petition/research_findings.htm signatures still until 2020).


In turn, there are also many studies that show a positive effect of computer-based feedback on learners’ writing products (e. g. with regard to a before/after revision or an effect of first-draft performance with a positive “transfer effect” on later writing; Lachner & Neuburg, 2018; Lachner, Burkhart, & Nückles, 2017). Most studies on computer-based feedback on writing, however, only explore the effects of a particular feedback-tool (Wilson & Czik, 2016;  Ranalli, Link, & Chukharev-Hudilainen, 2017) in terms of one or more aspects of feedback (e. g. overall text quality score, text comprehension or cohesion). Research syntheses on this topic are rarely available.  
  
Stevenson & Phakiti (2014) conducted a meta-analyses about the effects of computer-generated feedback on the quality of writing. They come to the conclusion the research on computer-based feedback on writing is very heterogeneous and the studies exist unconnected from each other. They state that it is necessary to investigate further whether “it is really the source of the feedback that matters, or whether it is other factors such as the way it is delivered, and the nature of the feedback provided that makes the difference” (p. 63). Hence it is unclear which __features of feedback__ are related with learning achievement and related constructs. In their current meta-analysis of the effects of feedback on student learning, Wisniewski, Zierer, & Hattie (2020) further emphasize this claim. What is more, Stevenson & Phakiti (2014) note that, so far, the analyses focused on the written production measures and that the effects of computer-based feedback on writing processes or perceived usefulness were not considered.  
  
Especially in times of home schooling (e.g. due to Covid 19) computer-based feedback is very relevant and can support teachers in their teaching and students in their individual learning processes (Shute, 2008; Wisniewski, Zierer, & Hattie, 2020). However, literature lacks of an overview of the current heterogeneous research, which shows 1) __what__ different feedback tools give feedback __on__ (Patchan, Schunn, & Correnti, 2016), 2) __how__ feedback is given using these tools (Hattie & Timperley, 2007) and 3) which tools are didactically developed to support students’ learning process. Therefore, we conduct a systematic review with the aims to show possible advancements in the last 17 years, to systematize the heterogeneous research landscape and to give practical implications.

  

## Research Questions

<button data-toggle="collapse" data-target="#rq">more info</button>
<div id="rq" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Provide an explicit statement of the question(s) the review will address with reference to participants, interventions, comparators, and outcomes (PICO)",
                                            # PROSPERO
                                            "State the question(s) to be addressed by the review, clearly and precisely. Review questions may be specific or broad. It may be appropriate to break very broad questions down into a series of related more specific questions. Questions may be framed or refined using PI(E)COS where relevant.",
                                            # MARS
                                            "Objectives: State the hypotheses examined, indicating which were prespecified, including

* Question in terms of relevant participant characteristics (including animal populations), independent variables (experimental manipulations, treatments, or interventions), ruling out of possible confounding variables, dependent variables (outcomes, criterion), and other features of study designs
* Method(s) of synthesis and if meta-analysis was used, the specific methods used to integrate studies (e.g., effect-size metric, averaging method, the model used in homogeneity analysis)"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 
We want to investigate 1) __what__ different feedback tools give feedback __on__ (Patchan, Schunn, & Correnti, 2016), 2) __how__ feedback is given using these tools (Hattie & Timperley, 2007) and 3) which tools are didactically developed to support students’ learning process. With this systematic review we want to explore possible advancements of the last 17 years, and we want to systematize the heterogeneous research landscape and to give practical implications to support computer-based teaching and learning.

# Methods


## Eligibility: Inclusion and Exclusion Criteria 

<button data-toggle="collapse" data-target="#eiaec">more info</button>
<div id="eiaec" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Specify the study characteristics (such as PICO, study design, setting, time frame) and report characteristics (such as years considered, language, publication status) to be used as criteria for eligibility for the review",
                                            # PROSPERO
                                            "Give details of the types of study (study designs) eligible for inclusion in the review. If there are no restrictions on the types of study design eligible for inclusion, or certain study types are excluded, this should be stated. The preferred format includes details of both inclusion and exclusion criteria.",
                                            # MARS
                                            "Describe the criteria for selecting studies, including

* Independent variables (e.g., experimental manipulations, types of treatments or interventions or predictor variables)
* Dependent variable (e.g., outcomes, in syntheses of clinical research including both potential benefits and potential adverse effects)
* Eligible study designs (e.g., methods of sampling or treatment assignment)
* Handling of multiple reports about the same study or sample, describing which are primary and handling of multiple measures using the same participants
* Restrictions on study inclusion (e.g., by study age, language, location, or report type)
* Changes to the prespecified inclusion and exclusion criteria, and when these changes were made
* Handling of reports that did not contain sufficient information to judge eligibility (e.g., lacking information about study design) and reports that did not include sufficient information for analysis (e.g., did not report numerical data about those outcomes)"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

### Inclusion criteria

__PICOS__  

* Population: 
  - formal learning context (planned as a learning activity to improve writing skills)
  - L1 (first language)
  - years: 2003 and younger (rationale see 'Search Strategy')
* Intervention: 
  - system/ computer generated feedback
  - formative feedback
  - immediate feedback
  - targeted at improving writing
* Comparison/ Control:
  - none
* Outcome: improvement of text quality
  - cohesion (organization)
  - comprehension/ comprehensability
  - lexical measures
  - sentence structure (variety of sentences)
  - overall development (awareness of purpose, task, and audience)
  - (different!) overall quality scores
  - specifity (Problems, solutions, locatization)
* Study Type
  - empirical (quantitative and qualitative)

### Exclusion criteria

__PICOS__  

* Population: 
  - no formal learning context (e.g. novel writing; diary writing)
  - not in the context of writing
  - L2 learning (second language learning)
* Intervention: 
  - peer feedback
  - summative feedback
  - delayed feedback
  - teacher feedback using computer tools (mediated feedback)
  - targeted at improving content learning
* Comparison/ Control:
  - not empirical
* Outcome: 
  - does not focus text quality
  - conceptual content knowledge
* Study Type
  - purely conceptual

## Sources of Search: List and Rationale

<button data-toggle="collapse" data-target="#soslar">more info</button>
<div id="soslar" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Searches: State the sources that will be searched. Give the search dates, and any restrictions (e.g. language or
publication period). Do NOT enter the full search strategy (it may be provided as a link or attachment.)",
                                            # MARS
                                            "Describe all information sources:

* Databases searched (e.g., PsycINFO, ClinicalTrials.gov), including dates of coverage (i.e., earliest and latest records included in the search), and software and search platforms used
* Names of specific journals that were searched and the volumes checked
* Explanation of rationale for choosing reference lists if examined (e.g., other relevant articles, previous research
syntheses)
* Documents for which forward (citation) searches were conducted, stating why these documents were chosen
* Number of researchers contacted if study authors or individual researchers were contacted to find studies or to obtain more information about included studies, as well as criteria for making contact (e.g., previous relevant publications), and response rate
* Dates of contact if other direct contact searches were conducted such as contacting corporate sponsors or mailings to distribution lists
* Search strategies in addition to those above and the results of these searches"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

* specific target journals (check if indexed anyway) with search term
  - all target journals are indexed in one of the data bases (ERIC, PsycINFO or Web of Science)
* data bases:
  - ERIC
  - PsycINFO
  - Web of Science
  - first 100 results from google scholar
* backwards search from articles:
  - After screening abstracts and titles: We use the three latest synthesis articles (reviews or metaanalyses) and screen their references
* preprint server
  - PsychArchives
  - PsyArXiv & SocArXiv

## Search Strategy

<button data-toggle="collapse" data-target="#searchs">more info</button>
<div id="searchs" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Present draft of search strategy to be used for at least one electronic database, including planned limits, such that it could be repeated.",
                                            # PROSPERO
                                            "URL to search strategy: Give a link to a published pdf/word document detailing either the search strategy or an example of a search strategy for a specific database if available (including the keywords that will be used in the search strategies), or upload your search strategy. Do NOT provide links to your search results. Alternatively, upload your search strategy to CRD in pdf format. Please note that by doing so you are consenting to the file being made publicly accessible.",
                                            # MARS
                                            "Describe all information sources: Search strategies of electronic searches, such that they could be repeated (e.g., include the search terms used, Boolean connectors, fields searched, explosion of terms)."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

__Search String: PICO__  

* Participants: `NOT (peer  OR medic*  OR neural-network  OR health*  OR care*)`
* Intervention: `((computer*  OR automat*)  AND (writ*  AND (argument*  OR essay*  OR summary  OR exposit*  OR expla*))  AND (feedback  OR evaluat*  OR assess*  OR scor*)`
* Control: _none_
* Outcome: _none_

__Timespan:__  
2003 - 2020  
Around 2003 several programs were either established of got a major upgrade (see below). Before this timeframe, programs were rarely powered by machine learning (or related) algorythms. They had less or different range of functions and were thus different programs. We therefore choose this timeframe to make make analyses more comparable and reduce bias. 

Examples:

* MyAccess: established in 2003
* Project Essay Grade: Bought by Measurement, Inc. in 2002/2003 and subsequently utilized AI scoring engine
* Citerion: major upgrade of scoring engine from e-rater V1.3 to e-rater V2.0 in 2004 (Attali & Burstein, 2004)
* Summary Street: established between 2002 and 2004 (Wade-Stein & Kintsch, 2004)



## Data Management Tools Used

<button data-toggle="collapse" data-target="#dmtu">more info</button>
<div id="dmtu" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe the mechanism(s) that will be used to manage records and data throughout the review.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

- Mendeley (Reference Management) to collect and sort out the search results from the data bases
- Rayyan (https://rayyan.qcri.org/welcome) to include or exclude articles by several raters


## Selection of Studies

<button data-toggle="collapse" data-target="#desos">more info</button>
<div id="desos" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "State the process that will be used for selecting studies (such as two independent reviewers) through each phase of the review (that is, screening, eligibility and inclusion in meta-analysis).",
                                            # PROSPERO
                                            "Data extraction (selection and coding): Describe how studies will be selected for inclusion. State what data will be extracted or obtained. State how this will be done and recorded.",
                                            # MARS
                                            "Describe the process for deciding which studies would be included in the syntheses and/or included in the meta-analysis, including

* Document elements (e.g., title, abstract, full text) used to make decisions about inclusion or exclusion from the synthesis at each step of the screening process 
* Qualifications (e.g., training, educational or professional status) of those who conducted each step in the study selection process, stating whether each step was conducted by a single person or in duplicate as well as an explanation of how reliability was assessed if one screener was used and how disagreements were resolved if multiple were used."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Two independent reviewers conduct every of the following steps:

Process of revison:

  1) screening titles and if we cannot make a statement based on the title we will screen the abstract
  2) screening all abstracts
  3) screening full texts

At each of this three steps articles will be selected for inclusion if the inclusion criteria apply and none of the exclusivity criteria apply. If this is not the case articles will be excluded. 
If it is not clearly wheter articles should be included or excluded these studies will be marked as "maybe" and will be discussed with both reviewer together at the end. 
Articles will also be discussed together of both of the reviewers if there were disagreements. This disagreements were resolved by screening the full texts using the inclusion criteria.


## Method of Extracting Data & Information (from Reports)

<button data-toggle="collapse" data-target="#edfr">more info</button>
<div id="edfr" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe planned method of extracting data from reports (such as piloting forms, done independently, in duplicate), any processes for obtaining and confirming data from investigators.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Describe methods of extracting data from reports, including 

* Variables for which data were sought and the variable categories 
* Qualifications of those who conducted each step in the data extraction process, stating whether each step was conducted by a single person or in duplicate and an explanation of how reliability was assessed if one screener was used and how disagreements were resolved if multiple screeners were used as well as whether data coding forms, instructions for completion, and the data (including metadata) are available, stating where they can be found (e.g., public registry, supplemental materials)"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

* Studies will be coded in Rayyan as far as possible.
* Beyond that: Both reviewers either use a standardized Excel form or a self-programmed dashboard that produces a relational database.
* After data input both reviewers check for consistency and discuss discrepancies.



## List and Description of Data and Information Extracted

<button data-toggle="collapse" data-target="#ladodaie">more info</button>
<div id="ladodaie" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "
* List and define all variables for which data will be sought (such as PICO items, funding sources), any pre-planned data assumptions and simplifications
* List and define all outcomes for which data will be sought, including prioritization of main and additional outcomes, with rationale",
                                            # PROSPERO
                                            "
* Condition or domain being studied: Give a short description of the disease, condition or healthcare domain being studied. This could include health and wellbeing outcomes.
* Participants/population: Give summary criteria for the participants or populations being studied by the review. The preferred format includes details of both inclusion and exclusion criteria.
* Intervention(s), exposure(s): Give full and clear descriptions or definitions of the nature of the interventions or the exposures to be reviewed.
* Comparator(s)/control: Where relevant, give details of the alternatives against which the main subject/topic of the review will be compared (e.g. another intervention or a non-exposed control group). The preferred format includes details of both inclusion and exclusion criteria.
* Main and additional outcome(s): Give the pre-specified main (most important) outcomes of the review, including details of how the outcome is defined and measured and when these measurement are made, if these are part of the review inclusion criteria.
* Measures of effect: Please specify the effect measure(s) for you main outcome(s) e.g. relative risks, odds ratios, risk difference,
and/or 'number needed to treat.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

* publication status [scholarly published, grey literature]
* visual presentation of feedback [grafical, text, mixed]
* specifity [problem, solution, localization]
* summarization
* explanation
* scope
* content focus (success criteria) of feedback [lower order, higher order]
* tool/software used
* quantitative empirical studies
  - sample size
  - geographic location
  - condition characteristics
  - measured construct
  - effect size
  


## Effect size transformation from individual studies

<button data-toggle="collapse" data-target="#estfis">more info</button>
<div id="estfis" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Not specified.",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Describe the statistical methods for calculating effect sizes, including the metric(s) used (e.g., correlation coefficients,
differences in means, risk ratios) and formula(s) used to calculate effect sizes."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

It is unlikely that meta-anylsis will be possible due to lack of quantitative empirical studies that fulfill our quality standards. If meta-analysis is possible we will convert effect sizes based on Polanin & Snilstveit (https://doi.org/10.4073/cmpn.2016.3).


## Risk of Bias in Individual Studies

<button data-toggle="collapse" data-target="#robiis">more info</button>
<div id="robiis" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe anticipated methods for assessing risk of bias of individual studies, including whether this will be done at the outcome or study level, or both; state how this information will be used in data synthesis",
                                            # PROSPERO
                                            "Risk of bias (quality) assessment: Describe the method of assessing risk of bias or quality assessment. State which characteristics of the studies will be assessed and any formal risk of bias tools that will be used.",
                                            # MARS
                                            "Describe any methods used to assess risk to internal validity in individual study results, including

* Risks assessed and criteria for concluding risk exists or does not exist
* Methods for including risk to internal validity in the decisions to synthesize of the data and the interpretation of results"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

We will use a subset of the items/ dimensions from study DIAD (Valentine & Cooper, 2008).


# Results


## Strategy for Data Sythesis

<button data-toggle="collapse" data-target="#sfds">more info</button>
<div id="sfds" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "
* Describe criteria under which study data will be quantitatively synthesised.
* If data are appropriate for quantitative synthesis, describe planned summary measures, methods of handling data and methods of combining data from studies, including any planned exploration of consistency (such as I2, Kendall’s τ)
* If quantitative synthesis is not appropriate, describe the type of summary planned",
                                            # PROSPERO
                                            "Strategy for data synthesis: Provide details of the planned synthesis including a rationale for the methods selected. This must not be generic text but should be specific to your review and describe how the proposed analysis will be applied to your data.",
                                            # MARS
                                            "Describe narrative and statistical methods used to compare studies. If meta-analysis was conducted, describe the methods used to combine effects across studies and the model used to estimate the heterogeneity of the effects sizes (e.g., a fixed-effect, random-effects model robust variance estimation), including

* Rationale for the method of synthesis
* Methods for weighting study results
* Methods to estimate imprecision (e.g., confidence or credibility intervals) both within and between studies
* Description of all transformations or corrections (e.g., to account for small samples or unequal group numbers) and adjustments (e.g., for clustering, missing data, measurement artifacts, or construct-level relationships) made to the data and justification for these
* Additional analyses (e.g., subgroup analyses, meta-regression), including whether each analysis was prespecified or post hoc
* Selection of prior distributions and assessment of model fit if Bayesian analyses were conducted
* Name and version number of computer programs used for the analysis
* Statistical code and where it can be found (e.g., a supplement)"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

It is unlikely that meta-analysis will be possible.  
   
The aim of the review is to map the scientific literature concerning computer-based feedback on writing, to describe which tools are available, what type and the content of feedback they give and the amout of research volume available.  
  
As the review includes qualitative as well as quantitative studies, strategies of narrative summarizing will be applied. 


## Moderators/ Subgroups

<button data-toggle="collapse" data-target="#modarat">more info</button>
<div id="modarat" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe any proposed additional analyses (such as sensitivity or subgroup analyses, meta-regression)",
                                            # PROSPERO
                                            "Analysis of subgroups or subsets: State any planned investigation of ‘subgroups’. Be clear and specific about which type of study or participant will be included in each group or covariate investigated. State the planned analytic approach.",
                                            # MARS
                                            "Not specified."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

__main categorization__  

* visual presentation of feedback [grafical, text, mixed]
* specifity [problem, solution, localization]
* summarization
* explanation
* scope
* content focus (success criteria) of feedback [lower order, higher order]
* tool/software used

__categorization for further description__  

* Side of Recipients:
  - prerequisite of the sample/ target group (gender, age, grade, experience, motivation, writing ability, self concept)
  - process (cognitive load, understanding, editing time, text length)
  - implementation/ use of feedback
* Side of the Agent
  - intention of use



## Assessment of Publication Bias

<button data-toggle="collapse" data-target="#aopb">more info</button>
<div id="aopb" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Specify any planned assessment of meta-bias(es) (such as publication bias across studies, selective reporting within studies)",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Describe risk of bias across studies, including

* Statement about whether
   (a) unpublished studies and unreported data, or 
   (b) only published data were included in the synthesis and the rationale if only published data were used
* Assessments of the impact of publication bias (e.g., modeling of data censoring, trim-and-fill analysis)
* Results of any statistical analyses looking for selective reporting of results within studies"))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Grey literature will be included (see sources of search).  
As there will be likely no meta-analysis, we will not be able to assess publication bias quantitatively.


# Discussion


## Strength of Cumulative Evidence

<button data-toggle="collapse" data-target="#stroe">more info</button>
<div id="stroe" class="collapse">

```{r}
# avoiding markdown tables because they're not exactly the prettiest flower in the bunch
# set up the table
table_sources <- data.frame(source = c("PRISMA-P",     # first column will be always the same
                                       "PROSPERO", 
                                       "MARS"),
                            description = c(# PRISMA-P
                                            "Describe how the strength of the body of evidence will be assessed (such as GRADE).",
                                            # PROSPERO
                                            "Not specified.",
                                            # MARS
                                            "Describe the generalizability (external validity) of conclusions, including • Implications for related populations, intervention variations, dependent (outcome) variables."))

# produce table
knitr::kable(table_sources) %>%
    kable_styling(fixed_thead = T) %>%
    column_spec(1, bold = T) %>%
    row_spec(0, background = "#ececec")
```

</div> 

Evidence is a concept from quantitative empirical research, however, our review also includes qualitative studies.  
If we include a meta-analysis in the review (see above), we will be evaluating the strength of evidence based on dimensions that apply to our review from the GRADE (Grading of Recommendations Assessment, Development and Evaluation) approach.